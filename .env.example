# ========================================
# API CONFIGURATION
# ========================================

# Single OpenAI API Key (for backwards compatibility)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-key-here

# Multiple API Keys (NEW - for parallel execution load balancing)
# Comma-separated list of API keys for 3-10× speedup
# Example: OPENAI_API_KEYS=sk-key1,sk-key2,sk-key3
# If set, this overrides OPENAI_API_KEY
# OPENAI_API_KEYS=sk-key1,sk-key2,sk-key3

# Rate limit per key in requests per minute (default: 500 for Tier 1)
# Adjust based on your OpenAI tier:
# - Free tier: 3 RPM
# - Tier 1: 500 RPM
# - Tier 2: 5000 RPM
RATE_LIMIT_RPM=500

# Optional: Override model (default: gpt-4o-mini)
# OPENAI_MODEL=gpt-4o-mini

# ========================================
# PARALLEL EXECUTION (NEW - for speedup)
# ========================================

# Maximum number of episodes to run concurrently (default: 30)
# Adjust based on your API tier and number of keys:
# - Free tier (3 RPM, 1 key): MAX_CONCURRENT_EPISODES=2
# - Tier 1 (500 RPM, 1 key): MAX_CONCURRENT_EPISODES=10
# - Tier 1 (500 RPM, 3 keys): MAX_CONCURRENT_EPISODES=30
# - Tier 2 (5000 RPM, 3 keys): MAX_CONCURRENT_EPISODES=100
MAX_CONCURRENT_EPISODES=30

# Episodes per batch before checkpoint save (default: 100)
# Smaller values = more frequent checkpoints (safer but slower)
# Larger values = fewer checkpoints (faster but riskier)
BATCH_SIZE=100

# ========================================
# EVIDENCE EVALUATION
# ========================================

# Optional: Enable LLM-based evidence scoring (per-sentence then aggregate)
# Set to 1, true or yes to combine string match + LLM score for evidence_match_score
# Note: This increases API costs but improves evidence quality assessment
USE_LLM_EVIDENCE_EVAL=1

# ========================================
# EXPERIMENT CONFIGURATION
# ========================================

# Number of tasks to run per milestone (default: 500 for submission)
NUM_TASKS=500

# Number of FEVER samples to load (should be >= NUM_TASKS; default: 500)
NUM_SAMPLES=500

# Single run: random seed (default: 42)
SEED=42

# Multi-seed in one go: set SEEDS=42,123,456 to run all seeds then aggregate mean±std
# Example: SEEDS=42,123,456
# SEEDS=42,123,456

# ========================================
# PERFORMANCE EXPECTATIONS
# ========================================
#
# Sequential (1 key, no parallel):
#   - 500 tasks × 3 milestones = ~2-3 days
#
# Parallel (3 keys, 30 concurrent):
#   - 500 tasks × 3 milestones = ~2-4 hours
#   - Expected speedup: 12-18×
#
# Configuration examples:
#
# Free Tier (3 RPM, max 2 keys):
#   OPENAI_API_KEYS=sk-key1,sk-key2
#   RATE_LIMIT_RPM=3
#   MAX_CONCURRENT_EPISODES=3
#   Expected time: ~8-12 hours per seed
#
# Tier 1 (500 RPM, 3 keys):
#   OPENAI_API_KEYS=sk-key1,sk-key2,sk-key3
#   RATE_LIMIT_RPM=500
#   MAX_CONCURRENT_EPISODES=30
#   Expected time: 2-4 hours per seed
#
# Tier 2+ (5000 RPM, 5 keys):
#   OPENAI_API_KEYS=sk-key1,sk-key2,sk-key3,sk-key4,sk-key5
#   RATE_LIMIT_RPM=5000
#   MAX_CONCURRENT_EPISODES=100
#   Expected time: 20-30 minutes per seed
# ========================================
