experiment:
  name: "Milestone1_FEVER_P1"
  num_tasks: 100
  seed: 42

llm:
  provider: "openai"  # "openai" or "local"
  model: "gpt-4o"
  temperature: 0.7
  api_key_env: "OPENAI_API_KEY"  # environment variable name

dataset:
  name: "fever"
  split: "validation"
  num_samples: 100

protocol:
  name: "p1_evidence_first"

deviations:
  - "honest"
  - "no_evidence"

payoff:
  lambda_cost: 0.01   # cost weight
  mu_penalty: 0.5     # penalty weight for protocol violations

verifier:
  use_semantic_matching: false  # set to true to use sentence-transformers
  # Optional: use LLM to score each evidence sentence, then aggregate
  use_llm_evidence_eval: false
  evidence_score_weights:    # when use_llm_evidence_eval true: combine string_match + llm
    string_match: 0.5
    llm: 0.5

output:
  storage_type: "jsonl"
  path: "results/milestone1.jsonl"
  summary_path: "results/milestone1_summary.json"
